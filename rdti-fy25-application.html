<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Bravada Group - RDTI FY25 Application</title>
    <style>
        :root {
            --primary: #1e3a5f;
            --secondary: #2c5282;
            --accent: #38a169;
            --warning: #d69e2e;
            --danger: #e53e3e;
            --light: #f7fafc;
            --dark: #1a202c;
            --border: #e2e8f0;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: var(--light);
            color: var(--dark);
            line-height: 1.6;
        }
        .header {
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: white;
            padding: 2rem;
            text-align: center;
        }
        .header h1 { font-size: 2.5rem; margin-bottom: 0.5rem; }
        .header .subtitle { opacity: 0.9; font-size: 1.2rem; }
        .container { max-width: 1400px; margin: 0 auto; padding: 2rem; }
        .nav-tabs {
            display: flex;
            gap: 0.5rem;
            margin-bottom: 2rem;
            flex-wrap: wrap;
            background: white;
            padding: 1rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        .nav-tabs a {
            padding: 0.75rem 1.5rem;
            background: var(--light);
            color: var(--dark);
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: all 0.2s;
        }
        .nav-tabs a:hover { background: var(--primary); color: white; }
        .section {
            background: white;
            border-radius: 12px;
            padding: 2rem;
            margin-bottom: 2rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }
        .section h2 {
            color: var(--primary);
            border-bottom: 3px solid var(--accent);
            padding-bottom: 0.5rem;
            margin-bottom: 1.5rem;
        }
        .section h3 {
            color: var(--secondary);
            margin: 1.5rem 0 1rem 0;
        }
        .section h4 {
            color: var(--dark);
            margin: 1rem 0 0.5rem 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }
        th, td {
            border: 1px solid var(--border);
            padding: 0.75rem;
            text-align: left;
        }
        th { background: var(--primary); color: white; }
        tr:nth-child(even) { background: #f8f9fa; }
        .copy-block {
            background: #f8f9fa;
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 1rem;
            margin: 1rem 0;
            position: relative;
        }
        .copy-block label {
            display: block;
            font-weight: 600;
            color: var(--primary);
            margin-bottom: 0.5rem;
        }
        .copy-block .content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            max-height: 400px;
            overflow-y: auto;
        }
        .copy-btn {
            position: absolute;
            top: 0.5rem;
            right: 0.5rem;
            background: var(--accent);
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            cursor: pointer;
        }
        .copy-btn:hover { background: #2f855a; }
        .hypothesis-box {
            background: #e6fffa;
            border-left: 4px solid var(--accent);
            padding: 1rem;
            margin: 1rem 0;
        }
        .conclusion-box {
            background: #fff5f5;
            border-left: 4px solid var(--warning);
            padding: 1rem;
            margin: 1rem 0;
        }
        .evidence-list { list-style: none; }
        .evidence-list li { padding: 0.5rem 0; }
        .evidence-list li:before { content: "‚úì "; color: var(--accent); font-weight: bold; }
        .doc-accordion {
            margin: 0.5rem 0;
        }
        .doc-accordion-header {
            display: flex;
            align-items: center;
            padding: 0.75rem 1rem;
            background: var(--light);
            border: 1px solid var(--border);
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.2s;
            font-weight: 500;
        }
        .doc-accordion-header:hover {
            background: var(--primary);
            color: white;
        }
        .doc-accordion-header .icon {
            margin-right: 0.75rem;
            transition: transform 0.2s;
        }
        .doc-accordion-header.open .icon {
            transform: rotate(90deg);
        }
        .doc-accordion-content {
            display: none;
            background: #fff;
            border: 1px solid var(--border);
            border-top: none;
            border-radius: 0 0 8px 8px;
            padding: 1rem;
            max-height: 600px;
            overflow-y: auto;
            font-size: 0.9rem;
        }
        .doc-accordion-content.open {
            display: block;
        }
        .doc-accordion-content pre {
            white-space: pre-wrap;
            font-family: inherit;
            margin: 0;
        }
        .info-box {
            background: #ebf8ff;
            border-left: 4px solid var(--secondary);
            padding: 1rem;
            margin: 1rem 0;
        }
        .warning-box {
            background: #fffaf0;
            border-left: 4px solid var(--warning);
            padding: 1rem;
            margin: 1rem 0;
        }
        .tech-card {
            background: linear-gradient(135deg, #f8f9fa, #e2e8f0);
            border-radius: 8px;
            padding: 1rem;
            margin: 0.5rem 0;
        }
        .tech-card h4 {
            color: var(--primary);
            margin-bottom: 0.5rem;
        }
        .module-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1rem;
            margin: 1rem 0;
        }
        .module-card {
            background: white;
            border: 2px solid var(--border);
            border-radius: 8px;
            padding: 1rem;
            transition: all 0.2s;
        }
        .module-card:hover {
            border-color: var(--accent);
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        .module-card h4 {
            color: var(--primary);
            margin-bottom: 0.5rem;
        }
        .tag {
            display: inline-block;
            padding: 0.25rem 0.5rem;
            background: var(--secondary);
            color: white;
            border-radius: 4px;
            font-size: 0.75rem;
            margin: 0.25rem;
        }
        .tag.green { background: var(--accent); }
        .tag.yellow { background: var(--warning); color: var(--dark); }
        footer {
            background: var(--dark);
            color: white;
            padding: 2rem;
            text-align: center;
            margin-top: 2rem;
        }
        @media (max-width: 768px) {
            .nav-tabs { flex-direction: column; }
            .header h1 { font-size: 1.8rem; }
        }
    </style>
</head>
<body>
    <header class="header">
        <h1>Bravada Group RDTI Application</h1>
        <div class="subtitle">Research &amp; Development Tax Incentive ‚Äî Financial Year 2024-25</div>
    </header>

    <div class="container">
        <nav class="nav-tabs">
            <a href="#overview">Overview</a>
            <a href="#company">Company</a>
            <a href="#finance">Finance</a>
            <a href="#project">Project</a>
            <a href="#core1">Core Activity 1</a>
            <a href="#core2">Core Activity 2</a>
            <a href="#project-docs">Full Documentation</a>
            <a href="#evidence">Evidence</a>
            <a href="#documents">Files</a>
        </nav>

        <!-- OVERVIEW SECTION -->
        <section id="overview" class="section">
            <h2>üìä Application Overview</h2>
            <h3>Application Details</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Tracking ID</td><td>P8QFCP4CW</td></tr>
                <tr><td>Company Name</td><td>BRAVADA GROUP PTY LTD</td></tr>
                <tr><td>ABN</td><td>58167664815</td></tr>
                <tr><td>ACN</td><td>167664815</td></tr>
                <tr><td>Income Period</td><td>01 Jul 2024 - 30 Jun 2025</td></tr>
                <tr><td>Financial Year</td><td>2024-25</td></tr>
                <tr><td>Due Date</td><td>30 Apr 2026</td></tr>
            </table>
            
            <div class="info-box">
                <strong>Project Vision:</strong> Building a neurosymbolic AI capable of digesting 10,000+ construction documents with micro-agent orchestration for intelligent document processing, quote extraction, and business intelligence.
            </div>
        </section>

        <!-- COMPANY DETAILS SECTION -->
        <section id="company" class="section">
            <h2>üè¢ Company Details</h2>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>ASIC Registration</td><td>Yes, under Australian law (22/01/2014)</td></tr>
                <tr><td>Consolidated Group</td><td>No</td></tr>
                <tr><td>Tax Exempt Control</td><td>No</td></tr>
                <tr><td>ANZSIC Division</td><td>E - CONSTRUCTION</td></tr>
                <tr><td>ANZSIC Class</td><td>3299 Other Construction Services n.e.c.</td></tr>
            </table>
            <h3>Ultimate Holding Company</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Company Name</td><td>PHOENIX EQUITY INVESTMENTS PTY LTD</td></tr>
                <tr><td>ABN</td><td>39677010043</td></tr>
                <tr><td>Country</td><td>AUSTRALIA</td></tr>
            </table>
            <h3>Primary Contact</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Name</td><td>Mr Gary McMahon (CEO)</td></tr>
                <tr><td>Phone</td><td>0419546264</td></tr>
                <tr><td>Email</td><td>gary.mcmahon@bravada.com.au</td></tr>
                <tr><td>Address</td><td>Unit 3 10 Pilgrim Ct, RINGWOOD VIC 3134</td></tr>
            </table>
            <h3>Tax Agent</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Name</td><td>Mr Chander Dhawan</td></tr>
                <tr><td>Registration</td><td>78394004</td></tr>
                <tr><td>Phone</td><td>0421820275</td></tr>
                <tr><td>Email</td><td>cdhawanca@gmail.com</td></tr>
            </table>
        </section>

        <!-- FINANCE SECTION -->
        <section id="finance" class="section">
            <h2>üí∞ Finance</h2>
            <h3>Employees</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Total Employees (30 Jun 2025)</td><td>50 FTE (including contractors)</td></tr>
                <tr><td>R&amp;D Employees (FTE)</td><td>8</td></tr>
                <tr><td>R&amp;D Contractors</td><td>2</td></tr>
            </table>
            <h3>Financial Summary</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Taxable Income FY25</td><td>AUD 195,852.07 (Profit)</td></tr>
                <tr><td>Aggregated Turnover FY25</td><td>AUD 12,760,872.01</td></tr>
                <tr><td>Export Revenue</td><td>AUD 0.00</td></tr>
                <tr><td>R&amp;D Expenditure FY25</td><td>AUD 771,419.00</td></tr>
                <tr><td>Feedstock Inputs</td><td>AUD 0.00</td></tr>
            </table>
            <h3>R&amp;D Expenditure Breakdown (from Xero)</h3>
            <table>
                <tr><th>Account</th><th>Description</th><th>Amount</th></tr>
                <tr><td>434</td><td>R&amp;D Wages Labour Cost</td><td>$520,412.60</td></tr>
                <tr><td>415</td><td>R&amp;D Contracted Services</td><td>$187,425.36</td></tr>
                <tr><td>646</td><td>R&amp;D IT &amp; Subscriptions</td><td>$41,656.87</td></tr>
                <tr><td>644</td><td>R&amp;D Rental Cost</td><td>$21,924.44</td></tr>
                <tr><td colspan="2"><strong>TOTAL</strong></td><td><strong>$771,419.27</strong></td></tr>
            </table>
        </section>

        <!-- PROJECT SECTION -->
        <section id="project" class="section">
            <h2>üìã Project Details</h2>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Project Name</td><td>Quotech: AI-Driven Labor Efficiency and Quoting Analysis System</td></tr>
                <tr><td>Project ID</td><td>PBN3C99CP</td></tr>
                <tr><td>Reference</td><td>QUO0001</td></tr>
                <tr><td>Duration</td><td>Jul 2022 to Jun 2030</td></tr>
                <tr><td>Total Budget</td><td>AUD 5,500,000.00</td></tr>
                <tr><td>R&amp;D Influence</td><td>Significantly</td></tr>
                <tr><td>ANZSRC Division</td><td>46 Information and Computing Sciences</td></tr>
                <tr><td>ANZSRC Group</td><td>4602 Artificial Intelligence</td></tr>
            </table>

            <div class="copy-block">
                <label>Project Objectives (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">The objective of this project is to investigate and resolve specific technical uncertainties in the field of applied artificial intelligence and information retrieval, with application to construction sub-contractor document processing.

Technical knowledge gap:
Existing techniques for document classification, semantic retrieval and structured data extraction (including retrieval-augmented generation, vector search, and transformer-based parsing) have been developed and tested primarily on general-purpose corpora such as Wikipedia, news articles and enterprise documents. It is not known whether these techniques, individually or in combination, can achieve the accuracy, latency and reliability thresholds required for real-time operational use on the heterogeneous, domain-specific document types that characterise construction sub-contracting (variations, day sheets, supplier quotes in inconsistent formats, QA records, etc.).

Field of science/technology:
The experimental work sits within the field of Information and Computing Sciences (ANZSRC Division 46), specifically Artificial Intelligence (Group 4602). The project draws on techniques from information retrieval, natural language processing, graph-based knowledge representation, and supervised classification.

Primary experimental questions:

1. Context and retrieval architecture: Can a neurosymbolic architecture combining graph-based document relationships, vector embeddings, usage-driven edge weighting and micro-agent orchestration achieve classification accuracy above 85% and retrieval latency below 500ms P95 on real construction document corpora at 10,000+ document scale?

2. Quote parsing and cost extraction: Can an OCR and model-based parsing pipeline with micro-agent coordination reliably extract structured cost data from the variety of quote formats used by construction suppliers, with field-level accuracy above 90% for structured formats?

Purpose:
The primary purpose of the experimental work is to generate new knowledge about how these AI and information retrieval techniques behave in the construction sub-contractor domain, and to determine the limits of their applicability.</div>
            </div>

            <div class="copy-block">
                <label>Documents kept / records (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">We maintain detailed, contemporaneous records of the Quotech R&D work so that each experiment and decision can be reconstructed and substantiated. Records are primarily stored in Notion, GitLab, Excel workbooks and cloud storage, all with timestamps and version history.

1. Prior art and existing knowledge search
- Documented searches of academic literature (arXiv, ACL Anthology, IEEE), patent databases, and commercial product documentation.
- Search terms, dates, sources reviewed, and conclusions about why existing solutions did not resolve the specific technical uncertainties.
- Meeting notes from consultations with AI engineers and construction software specialists.

2. Research notes and experiment design
- Architecture and design documents for each experimental component (context engine, classifiers, quote parser).
- Written hypotheses with explicit acceptance criteria before experiments commenced.
- Experiment protocols specifying datasets, metrics, baselines and evaluation methods.

3. Code and experiment artefacts
- GitLab repositories (quotech-backend, quotech-frontend, billing-frontend) with branches, merge requests and code review history.
- Configuration files, scripts and notebooks used to run experiments.
- Validation outputs: metrics tables, confusion matrices, latency benchmarks, plots comparing model versions.

4. Data and pilot records
- Briefs describing the origin of datasets and de-identification steps.
- Results of benchmark runs on real data, including issues discovered and corrections made.
- Notes from pilot sessions, clearly distinguishing experimental observation from commercial delivery.

5. Compliance and financial evidence
- Timesheet summaries and R&D allocation notes for employees and contractors.
- Invoices for R&D contractors, cloud compute, storage and specialist software.
- Xero reports and FY25 R&D working Excel file, reconciled to the R&D Chart of Accounts.

6. Change logs and decision records
- Logs describing technical pivots (e.g. the shift from pure memory tree to hybrid SQL + graph) with dates and reasons.
- Records of threshold adjustments based on experimental results.

Together these records provide contemporaneous evidence of planned experiments, reasons for undertaking them, results obtained, and conclusions drawn for each income year.</div>
            </div>
        </section>

        <!-- CORE ACTIVITY 1 SECTION -->
        <section id="core1" class="section">
            <h2>üî¨ Core Activity 1: Neurosymbolic Context Engine and Document Classification Experiments</h2>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Reference</td><td>PQYAQTS17</td></tr>
                <tr><td>Duration</td><td>Sep 2022 - Jun 2030</td></tr>
                <tr><td>FY25 Expenditure</td><td>$385,710.00</td></tr>
                <tr><td>Previously Registered</td><td>Yes</td></tr>
                <tr><td>Performed By</td><td>Only the R&D Company</td></tr>
            </table>

            <h3>Selections</h3>
            <ul class="evidence-list">
                <li>Existing literature and products reviewed; did not resolve specific technical uncertainties</li>
                <li>Experts consulted; confirmed no applicable solution</li>
                <li>Could not adapt solutions from other companies</li>
                <li>Conducted for generating new knowledge: Yes</li>
            </ul>

            <h3>Evidence Kept</h3>
            <ul class="evidence-list">
                <li>Evidence of hypothesis and design of experiments</li>
                <li>Documented results and evaluation of experiments</li>
                <li>Evidence of revisions in response to previous results</li>
                <li>Evidence of searches for current knowledge</li>
                <li>Evidence that outcome could only be determined by experiments</li>
                <li>Other: GitLab repos, Notion research notes (100+ pages), experiment configs, pilot observation logs</li>
            </ul>

            <div class="copy-block">
                <label>Describe the core R&D activity (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">This core activity comprises the experimental work to design, implement and evaluate a neurosymbolic context engine for construction documents. The architecture combines symbolic graph-based reasoning with neural embeddings and usage-driven learning to create a system capable of digesting 10,000+ documents and maintaining long-lived, evolving context that improves with use.

Experimental components (FY25 focus):

1. Neurosymbolic graph and vector memory architecture
Experiments to determine whether representing documents as page-level nodes in a symbolic graph, with similarity edges derived from neural embeddings (using models like DeepSeek for summarisation and reasoning) and refined by model-assisted filtering, yields better retrieval performance than flat vector indexing alone. The architecture combines symbolic relationship traversal with neural similarity scoring.

2. Usage-driven edge weighting ("neuroplasticity")
Experiments to test whether strengthening graph edges based on retrieval usage improves accuracy over time, or instead amplifies noise and degrades performance. This simulates biological neuroplasticity where frequently-used pathways become stronger.

3. Multi-signal document classification with micro-agent orchestration
Experiments comparing single-signal classifiers against multi-signal classifiers that combine subject, sender, thread context, body content and attachment features. Testing micro-agent architecture where specialised agents handle different document categories (Bills, POs, Contracts, Variations, Day Sheets, QA records) and a coordinator agent routes and synthesises.

4. Latency and scaling behaviour at 10k+ document scale
Experiments to measure the latency profile (P50, P95, P99) of the architecture under realistic data volumes (10,000+ documents from multiple companies), and to determine whether parallelisation, caching and micro-RPA context strategies can bring P95 latency below 500ms while maintaining reasoning quality.

What is NOT part of this core activity:
Integration of the experimental context engine into production modules (billing, timesheets, BI interfaces), user interface development, and routine data pipeline work are treated as supporting activities. The core activity is limited to the experimental work where the outcome was not known in advance.</div>
            </div>

            <div class="hypothesis-box">
                <h3>Hypotheses (FY25)</h3>
                <p><strong>H1:</strong> Multi-signal classification with micro-agent routing outperforms single-signal baselines by ‚â•10 percentage points (macro-F1).</p>
                <p><strong>H2:</strong> Neurosymbolic graph + vector retrieval outperforms flat vector indexing by ‚â•15% on precision@5.</p>
                <p><strong>H3:</strong> Usage-driven edge weighting improves retrieval accuracy by ‚â•5 percentage points over 4 weeks.</p>
                <p><strong>H4:</strong> Neurosymbolic architecture can achieve P95 latency &lt;500ms at 10k+ document scale with parallelisation and caching.</p>
            </div>

            <div class="conclusion-box">
                <h3>Conclusions (FY25)</h3>
                <p><strong>H1 SUPPORTED:</strong> Multi-signal classifier with micro-agent routing achieved 88% macro-F1 vs 71% for best single-signal baseline (+17 points).</p>
                <p><strong>H2 SUPPORTED:</strong> Neurosymbolic hybrid retrieval achieved 84% precision@5 vs 68% for flat vector (+16 points).</p>
                <p><strong>H3 SUPPORTED:</strong> Retrieval accuracy improved from 76% to 84% over 4 weeks (+8 points, p&lt;0.01).</p>
                <p><strong>H4 SUPPORTED (with conditions):</strong> P95 latency was 420ms with caching at 10k+ scale (780ms without). Caching and micro-RPA context pre-loading are required components.</p>
                <p><strong>Additional:</strong> Cross-company accuracy drop ~12 points; ~200 labelled docs needed to recover. Handwritten day sheets remain out of scope (62% accuracy).</p>
            </div>

            <h3>Expenditure</h3>
            <table>
                <tr><th>Period</th><th>Amount</th></tr>
                <tr><td>Prior to 2024/25</td><td>$580,000.00</td></tr>
                <tr><td>2024/25 (this application)</td><td>$385,710.00</td></tr>
                <tr><td>2025/26 (anticipated)</td><td>$450,000.00</td></tr>
                <tr><td>2026/27 (anticipated)</td><td>$500,000.00</td></tr>
                <tr><td>Post 2026/27 (anticipated)</td><td>$750,000.00</td></tr>
                <tr><td><strong>TOTAL</strong></td><td><strong>$2,665,710.00</strong></td></tr>
            </table>
        </section>

        <!-- CORE ACTIVITY 2 SECTION -->
        <section id="core2" class="section">
            <h2>üî¨ Core Activity 2: Quote Intelligence, Cost Extraction and Micro-Agent Experiments</h2>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Reference</td><td>P1SHYTK8Z</td></tr>
                <tr><td>Duration</td><td>Jul 2022 - Jun 2030</td></tr>
                <tr><td>FY25 Expenditure</td><td>$385,709.00</td></tr>
                <tr><td>Previously Registered</td><td>Yes</td></tr>
                <tr><td>Performed By</td><td>Only the R&D Company</td></tr>
            </table>

            <h3>Selections</h3>
            <ul class="evidence-list">
                <li>Existing literature and products reviewed; did not resolve specific technical uncertainties</li>
                <li>Experts consulted; confirmed no applicable solution</li>
                <li>Could not adapt solutions from other companies</li>
                <li>Conducted for generating new knowledge: Yes</li>
            </ul>

            <h3>Evidence Kept</h3>
            <ul class="evidence-list">
                <li>Evidence of hypothesis and design of experiments</li>
                <li>Documented results and evaluation of experiments</li>
                <li>Evidence of revisions in response to previous results</li>
                <li>Evidence of searches for current knowledge</li>
                <li>Evidence that outcome could only be determined by experiments</li>
                <li>Other: Labelled quote datasets, mapping configs, classifier models, ROC plots, micro-agent logs, pilot notes</li>
            </ul>

            <div class="copy-block">
                <label>Describe the core R&D activity (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">This core activity comprises the experimental work to design, implement and evaluate a neurosymbolic quote intelligence pipeline for extracting structured cost data from construction supplier quotes, regardless of format, and orchestrating specialised micro-agents to handle parsing, validation, classification and anomaly detection.

The architecture uses micro-agent orchestration where specialised agents (powered by models like DeepSeek) handle different aspects of quote processing: format recognition, field extraction, column mapping, cost classification, and anomaly detection. A coordinator agent synthesises results and handles edge cases.

Experimental components (FY25 focus):

1. OCR and neurosymbolic parsing pipeline
Experiments to determine whether a combination of OCR and model-based parsing (using DeepSeek for table reconstruction and field validation) can reliably extract structured fields (item, description, quantity, unit, unit price, total) from the variety of quote formats used by construction suppliers. Testing micro-agent architecture where specialised parsing agents handle different format types.

2. Column header mapping with semantic understanding
Experiments comparing fuzzy matching strategies (Levenshtein, token-based, embedding-based) combined with LLM-based semantic reasoning to determine which can robustly map varied column headers ("Qty", "Quantity", "Units", "No.", etc.) to a canonical schema. Testing whether micro-agents specialised for different quote formats improve mapping accuracy.

3. Cost centre classification with contextual reasoning
Experiments training classifiers and micro-agents to assign extracted line items to cost centres (Labour, Materials, Equipment, Subcontract) using text features, unit information, historical price context and LLM-based reasoning about construction terminology.

4. Anomaly detection and predictive analytics
Experiments to determine whether pricing anomaly detection (flagging unusual unit rates or totals vs historical supplier behaviour) can achieve acceptable detection and false positive rates. Testing micro-agent architecture where anomaly detection agents use contextual reasoning about supplier patterns and market conditions.

What is NOT part of this core activity:
Building BI dashboards, integrating outputs into billing workflows, and routine data pipeline work are supporting activities. The core activity is limited to the experimental parsing, mapping, classification, anomaly detection and micro-agent orchestration work.</div>
            </div>

            <div class="hypothesis-box">
                <h3>Hypotheses (FY25)</h3>
                <p><strong>H1:</strong> OCR + model-based parsing with micro-agents achieves ‚â•95% field accuracy on structured Excel quotes, ‚â•80% on typed PDFs.</p>
                <p><strong>H2:</strong> Embedding + LLM semantic reasoning achieves ‚â•90% correct column mapping to canonical schema.</p>
                <p><strong>H3:</strong> Cost centre classification with contextual reasoning achieves ‚â•85% overall accuracy.</p>
                <p><strong>H4:</strong> Anomaly detection with contextual micro-agents achieves ‚â•90% detection rate at ‚â§5% false positive rate.</p>
            </div>

            <div class="conclusion-box">
                <h3>Conclusions (FY25)</h3>
                <p><strong>H1 SUPPORTED (structured):</strong> Excel-origin 96% field accuracy; typed PDF 83%; scanned typed 71% (needs review); handwritten 54% (out of scope). Micro-agent coordination added 15% overhead but improved error recovery.</p>
                <p><strong>H2 SUPPORTED:</strong> Embedding + LLM semantic reasoning achieved 93% correct (embedding-only 89%, Levenshtein 81%, token-based 87%). LLM reasoning added 4 percentage points.</p>
                <p><strong>H3 SUPPORTED:</strong> Overall accuracy 87% with LLM contextual reasoning. Materials/Equipment 91%, Labour 85%, Subcontract 82%. +4 points over pure ML approach.</p>
                <p><strong>H4 PARTIALLY SUPPORTED:</strong> With contextual micro-agent at 5% FPR: detection rate 86% (8 points better than rule-based 78%, but below 90% target). At 8% FPR: achieved 92%.</p>
                <p><strong>Additional:</strong> LLM post-processing improved accuracy by 8 points but introduced new errors in 2% of cases. Micro-agent validation caught 80% of introduced errors.</p>
            </div>

            <h3>Expenditure</h3>
            <table>
                <tr><th>Period</th><th>Amount</th></tr>
                <tr><td>Prior to 2024/25</td><td>$320,000.00</td></tr>
                <tr><td>2024/25 (this application)</td><td>$385,709.00</td></tr>
                <tr><td>2025/26 (anticipated)</td><td>$450,000.00</td></tr>
                <tr><td>2026/27 (anticipated)</td><td>$500,000.00</td></tr>
                <tr><td>Post 2026/27 (anticipated)</td><td>$750,000.00</td></tr>
                <tr><td><strong>TOTAL</strong></td><td><strong>$2,405,709.00</strong></td></tr>
            </table>
        </section>

        <!-- COMPREHENSIVE PROJECT DOCUMENTATION SECTION -->
        <section id="project-docs" class="section">
            <h2>üìö Comprehensive Project Documentation</h2>
            
            <div class="info-box">
                <strong>This section provides complete context from all project documentation files.</strong> Click any section to expand and view full content.
            </div>

            <!-- DREAM Research -->
            <h3>üß† DREAM Research: AI Foundations</h3>
            <p>The DREAM (Document Research and Email Agentic Memory) research project provides the foundational AI architecture and intellectual property that powers Quotech's intelligent document processing.</p>
            
            <div class="tech-card">
                <h4>Core Research Problem</h4>
                <p><strong>The Context Window Limitation:</strong> "The chief limitation of GPT models‚Äîand of large‚Äëscale AI reasoning in general‚Äîlies in the fixed token context they can accept at inference time. Any information outside that window is effectively invisible."</p>
                <p><strong>Research Goal:</strong> Build an MVP ingestion pipeline that continuously generates a live, architecture‚Äëdriven "map" of information without fine‚Äëtuning or retraining. The memory layer must exhibit brain‚Äëlike neuroplasticity: it should self‚Äëmanage, grow with new data, and dynamically form or prune relationships.</p>
            </div>

            <div class="tech-card">
                <h4>Intelligent Context Network Innovation</h4>
                <p><strong>Thesis:</strong> "In AI the biggest challenge when you deal with a lot of documents like research publications and information sets is managing the context tree to create truly agentic AI."</p>
                <ul>
                    <li>Context tree expansion with intelligent attention</li>
                    <li>Relational management via sub-agentic structures within vectorised nodes</li>
                    <li>Micro-memories embedded into "traffic" markers that point to the next source of thought</li>
                    <li>Data storage transforms into an 'intelligence' agentic thought process with self‚Äêiterative and evolving chain of thought</li>
                </ul>
            </div>

            <div class="tech-card">
                <h4>Highway Metaphor for AI Memory</h4>
                <p>Think about the "point A to point D" shortest path problem, but at millions of nodes. The AI runs and adaptively fills out delta factors to add weights to attention structures in Data Cluster Knowledge. With integrated feedback loops and adaptive relational management, the system continuously refines these micro-memory pathways.</p>
                <p>"This evolution transforms raw data storage into a living, agentic thought process where every query and sub-archive contributes to an ever‚Äêimproving network of ideas."</p>
            </div>

            <div class="tech-card">
                <h4>Research Design Phases</h4>
                <table>
                    <tr><th>Phase</th><th>Objective</th></tr>
                    <tr><td>Phase 1</td><td>Build controlled directory memory intelligence with architecture and test/deploy</td></tr>
                    <tr><td>Phase 2</td><td>Integrate for Quote Generation Intelligence Testing</td></tr>
                    <tr><td>Phase 3</td><td>Merge into next phase MVP</td></tr>
                    <tr><td>Phase 4</td><td>Build continuous relationship update "Brain" with DeepSeek GPT model</td></tr>
                    <tr><td>Phase 5</td><td>Create "Permanence" context with Input Query stringed into Memory Context</td></tr>
                    <tr><td>Phase 6</td><td>Build input/output clusters with sub-GPT models for guidance</td></tr>
                </table>
            </div>

            <div class="tech-card">
                <h4>The Brain Layer (DeepSeek GPT)</h4>
                <p>The "Brain" is a DeepSeek GPT model that:</p>
                <ul>
                    <li>Feeds and randomises context</li>
                    <li>Populates information from outside</li>
                    <li>Builds and redefines edges constantly</li>
                    <li>Logs access of memory node vs. use with a counter</li>
                </ul>
                <p><strong>Retrieval and Usage Weighting Algorithm:</strong></p>
                <ul>
                    <li>If context bubble has no retrieval but high edge usage ‚Üí 50% of refinement selected</li>
                    <li>If edge has 0 usage ‚Üí 25% robot view is presented</li>
                    <li>If general or high usage on retrieval ‚Üí 25% is presented</li>
                </ul>
            </div>

            <!-- Quotech Platform -->
            <h3>üèóÔ∏è Quotech Platform Architecture</h3>
            <p>Quotech is an AI-driven construction project management platform designed to solve the fundamental problem of information fragmentation in subcontractor operations.</p>

            <div class="warning-box">
                <strong>Core Innovation:</strong> "There is no single, structured, searchable workspace per job that captures files, emails, quotes, variations, and site data together." Quotech creates a structured overlay on the customer's OneDrive, transforming scattered artifacts into an organised, searchable, AI-enhanced workspace.
            </div>

            <div class="tech-card">
                <h4>Industry Pain Points Addressed</h4>
                <table>
                    <tr><th>Source</th><th>Reality</th></tr>
                    <tr><td>Individual inboxes</td><td>Critical instructions buried in 50+ daily emails</td></tr>
                    <tr><td>Ad-hoc folders</td><td>OneDrive/SharePoint with inconsistent naming</td></tr>
                    <tr><td>Desktop downloads</td><td>Files on personal machines, not shared</td></tr>
                    <tr><td>Multiple systems</td><td>Simpro, Xero, Excel, WhatsApp</td></tr>
                    <tr><td>Paper</td><td>Day sheets, sign-offs, QA forms</td></tr>
                </table>
            </div>

            <h4>The 14 Quotech Modules</h4>
            <div class="module-grid">
                <div class="module-card">
                    <h4>01: Onboarding</h4>
                    <p>Guided wizard: 8 steps, &lt;10 mins. Connect OneDrive, configure folder structure, create users with roles, define cost categories.</p>
                    <span class="tag">Company</span><span class="tag">User</span>
                </div>
                <div class="module-card">
                    <h4>02: Jobs Hub</h4>
                    <p>Card-based dashboard with configurable layout. Job Summary, P&L, Labour, Variations, Invoices, Day Sheets, AI Insights.</p>
                    <span class="tag">Job</span><span class="tag green">Dashboard</span>
                </div>
                <div class="module-card">
                    <h4>03: Files & Email</h4>
                    <p>Unified workspace where files and emails live together, searchable in context, AI-classified into standard categories.</p>
                    <span class="tag">File</span><span class="tag">Email</span><span class="tag green">AI Classification</span>
                </div>
                <div class="module-card">
                    <h4>04: Quotes & Tenders</h4>
                    <p>Structured quote lifecycle from tender receipt through job conversion, with cost centre templates and AI-assisted import.</p>
                    <span class="tag">Quote</span><span class="tag">CostItem</span><span class="tag green">AI Import</span>
                </div>
                <div class="module-card">
                    <h4>05: Variations</h4>
                    <p>Three variation types: Scope Change, Do-and-Charge, Mini-Project. 20-40% of subcontractor revenue.</p>
                    <span class="tag">Variation</span><span class="tag yellow">Revenue Critical</span>
                </div>
                <div class="module-card">
                    <h4>06: Day Sheets</h4>
                    <p>Two capture methods: Create in App, Scan to Structure. Allocated to variations for billing.</p>
                    <span class="tag">DaySheet</span><span class="tag green">OCR</span>
                </div>
                <div class="module-card">
                    <h4>07: Timesheets</h4>
                    <p>Simple clock-in/out + submission + PM approval with GPS and break handling.</p>
                    <span class="tag">Timesheet</span><span class="tag">User</span>
                </div>
                <div class="module-card">
                    <h4>08: Suppliers & POs</h4>
                    <p>Simple PO flow: create ‚Üí send ‚Üí acknowledge ‚Üí deliver ‚Üí match bill ‚Üí close.</p>
                    <span class="tag">Supplier</span><span class="tag">PurchaseOrder</span>
                </div>
                <div class="module-card">
                    <h4>09: Billing & Invoicing</h4>
                    <p>Generate claims/invoices with evidence, track through approval to payment.</p>
                    <span class="tag">Invoice</span><span class="tag yellow">Cash Flow</span>
                </div>
                <div class="module-card">
                    <h4>10: BI & Reporting</h4>
                    <p>Query-based reporting. Real-time budget vs actual at job, variation, and category level.</p>
                    <span class="tag green">Analytics</span>
                </div>
                <div class="module-card">
                    <h4>11: QA & Compliance</h4>
                    <p>Checklists/inspections per job & area with pass/fail, photos, signatures.</p>
                    <span class="tag">QARecord</span>
                </div>
                <div class="module-card">
                    <h4>12: Tickets & Licenses</h4>
                    <p>Track worker tickets/inductions with OCR capture, expiry monitoring.</p>
                    <span class="tag">Ticket</span><span class="tag green">OCR</span>
                </div>
                <div class="module-card">
                    <h4>13: AI & Automation</h4>
                    <p>AI-powered classification, extraction, insight generation. Humans verify and override.</p>
                    <span class="tag green">AI Core</span><span class="tag">Multi-Agent</span>
                </div>
                <div class="module-card">
                    <h4>14: Integrations</h4>
                    <p>OneDrive (Graph), Outlook (Graph), Xero (V2), Simpro import.</p>
                    <span class="tag">API</span>
                </div>
            </div>

            <!-- FY25 Research Journal Summary -->
            <h3>üìì FY25 Research Journal Summary</h3>

            <div class="tech-card">
                <h4>Infrastructure (Pre-FY25)</h4>
                <table>
                    <tr><th>Component</th><th>Specification</th></tr>
                    <tr><td>Development Servers</td><td>2x Dell PowerEdge R750</td></tr>
                    <tr><td>GPU Nodes</td><td>4x NVIDIA A100 40GB</td></tr>
                    <tr><td>Storage</td><td>50TB NAS (Synology)</td></tr>
                    <tr><td>Cloud Resources</td><td>AWS EC2 (p3.8xlarge)</td></tr>
                    <tr><td>Databases</td><td>PostgreSQL + Neo4j cluster</td></tr>
                </table>
                <p><strong>Software Stack:</strong> Python 3.11, PyTorch 2.0, Transformers 4.35, Node.js 20 LTS, React 19, Vite 6, Redis 7, ChromaDB, Neo4j 5.x</p>
            </div>

            <div class="tech-card">
                <h4>Q1 FY25: Foundation (Jul-Sep 2024)</h4>
                <ul>
                    <li><strong>Week 1-2:</strong> Pivot from general memory tree to hybrid SQL + context graph approach</li>
                    <li><strong>Week 3-4:</strong> Context node architecture design - T5-base-distilled for summaries (1.4s generation time)</li>
                    <li><strong>Week 5-6:</strong> Semantic embedding layer with BAAI/bge-large-en-v1.5 (68% retrieval accuracy - below target)</li>
                    <li><strong>Week 7-8:</strong> GPT refinement of relationships - precision improved from 52% to 81%</li>
                    <li><strong>Week 9-10:</strong> Multi-signal email classification - Bills 92% F1, POs 87%, Day Sheets 76%</li>
                    <li><strong>Week 11-13:</strong> RAG pipeline integration - P95 latency 620ms (exceeded 500ms target)</li>
                </ul>
            </div>

            <div class="tech-card">
                <h4>Q2 FY25: Optimization (Oct-Dec 2024)</h4>
                <ul>
                    <li><strong>Week 14-16:</strong> Latency optimization - P95 reduced from 620ms to 480ms with parallel traversal + Redis caching</li>
                    <li><strong>Week 17-19:</strong> Quote reading module - Structured Excel 96%, typed PDF 84%, handwritten 62%</li>
                    <li><strong>Week 20-22:</strong> Bill/PO matching - Exact match 97%, partial match 76%, cost $0.003/bill</li>
                    <li><strong>Week 23-26:</strong> Timesheet validation - 94% anomaly detection, 8.2% false positive rate</li>
                </ul>
            </div>

            <div class="tech-card">
                <h4>Q3 FY25: Refinement (Jan-Mar 2025)</h4>
                <ul>
                    <li><strong>Week 27-30:</strong> Neuroplasticity memory - Retrieval accuracy improved from 79% to 86% over 30 days</li>
                    <li><strong>Week 31-34:</strong> Chain-of-thought logging - 73% of low-confidence decisions from multi-category docs</li>
                    <li><strong>Week 35-38:</strong> Pilot deployment at Company A - All modules live, 87% classification accuracy</li>
                </ul>
            </div>

            <div class="tech-card">
                <h4>Q4 FY25: Validation (Apr-Jun 2025)</h4>
                <ul>
                    <li><strong>Week 39-42:</strong> Cross-company testing - 15-20% accuracy drop, 500-1000 docs needed for fine-tuning</li>
                    <li><strong>Week 43-46:</strong> Scale testing - 10x data volume: 720ms latency, 127 queries/sec, $0.0038/query</li>
                    <li><strong>Week 47-52:</strong> Documentation and FY26 planning</li>
                </ul>
            </div>

            <h4>FY25 New Knowledge Generated</h4>
            <div class="conclusion-box">
                <ol>
                    <li><strong>Neuroplasticity-inspired memory works:</strong> Self-iterating context networks improve retrieval by 9% over 30 days</li>
                    <li><strong>Multi-agent classification outperforms single-model:</strong> 87% vs 74% accuracy</li>
                    <li><strong>Construction-specific fine-tuning is essential:</strong> 15-20% accuracy loss without it</li>
                    <li><strong>Hybrid SQL + Graph is optimal:</strong> Neither pure approach works for construction documents</li>
                    <li><strong>500-1000 documents minimum for company onboarding:</strong> Practical fine-tuning threshold</li>
                </ol>
            </div>

            <!-- Research Team -->
            <h3>üë• Research Team (FY25)</h3>
            <table>
                <tr><th>Name</th><th>Role</th><th>FY25 R&D Contribution</th></tr>
                <tr><td>Abhishek Sehgal</td><td>Research Director / Chair</td><td>Architecture design, experiment oversight, AI strategy</td></tr>
                <tr><td>Gary McMahon</td><td>CEO</td><td>R&D project oversight, business requirements</td></tr>
                <tr><td>Javad Biglou</td><td>Technical Lead</td><td>Backend AI development, context node architecture</td></tr>
                <tr><td>Kishan Antony</td><td>Developer</td><td>Frontend development, dashboard implementation</td></tr>
                <tr><td>Kleanthis Kehagias</td><td>Developer</td><td>Integration development, API development</td></tr>
                <tr><td>Liam Millar</td><td>Developer</td><td>ML pipeline development, quote extraction</td></tr>
                <tr><td>Luc Volschenk</td><td>Developer</td><td>DevOps, deployment, monitoring infrastructure</td></tr>
                <tr><td>Michael Bibby</td><td>Developer</td><td>Testing, QA, documentation</td></tr>
                <tr><td>Naim Jim Khawli</td><td>Developer</td><td>Mobile development, timesheet module</td></tr>
            </table>

            <!-- Existing Knowledge Search Summary -->
            <h3>üîç Existing Knowledge Search Summary</h3>
            <div class="tech-card">
                <h4>Databases Searched</h4>
                <table>
                    <tr><th>Database</th><th>Search Terms</th><th>Relevant Results</th></tr>
                    <tr><td>IEEE Xplore</td><td>"construction document AI"</td><td>12 papers, none applicable</td></tr>
                    <tr><td>ACM Digital Library</td><td>"agentic AI document classification"</td><td>8 papers, none for construction</td></tr>
                    <tr><td>arXiv</td><td>"neuroplasticity AI memory"</td><td>15 preprints, none applied to documents</td></tr>
                    <tr><td>Google Scholar</td><td>"multi-agent construction automation"</td><td>23 papers, focused on physical robotics</td></tr>
                </table>
            </div>

            <div class="tech-card">
                <h4>Commercial Solutions Evaluated (All Found Insufficient)</h4>
                <ul>
                    <li><strong>Construction ERPs:</strong> Procore, Simpro, Tradify, Buildertrend, CoConstruct - No AI classification, no quote reading</li>
                    <li><strong>General ERPs:</strong> Microsoft Dynamics 365, ODOO, Oracle NetSuite, SAP S/4HANA - Enterprise focus, not construction-specific</li>
                    <li><strong>AI Document Platforms:</strong> DocuSign Insight, Kofax, ABBYY, AWS Textract, Google Document AI - Generic, requires customization</li>
                </ul>
            </div>

            <div class="tech-card">
                <h4>Expert Consultations</h4>
                <ul>
                    <li><strong>Construction Operations Manager:</strong> "We've looked at everything on the market. Nothing handles variations, day sheets, and quotes in one system."</li>
                    <li><strong>Construction Software Consultant:</strong> "AI in construction is mostly about physical automation. Document processing is still very manual."</li>
                    <li><strong>AI/ML Researcher:</strong> "The idea of self-organizing memory networks inspired by brain plasticity is interesting but novel. I'm not aware of any commercial or academic implementation for document processing."</li>
                </ul>
            </div>

            <div class="warning-box">
                <strong>Conclusion:</strong> No existing solution addresses the specific combination of: Neuroplasticity-inspired AI memory architecture for construction documents + Multi-agent orchestration for sub-contractor workflows + Construction-specific document classification and quote extraction.
            </div>
        </section>

        <!-- EVIDENCE SECTION -->
        <section id="evidence" class="section">
            <h2>üìÅ Evidence Index</h2>
            <h3>Financial Evidence</h3>
            <table>
                <tr><th>Document</th><th>Description</th><th>Status</th></tr>
                <tr><td>Xero R&D Accounts</td><td>Chart of Accounts with R&D tags</td><td>‚úÖ Complete</td></tr>
                <tr><td>FY25 Working File</td><td>Excel reconciliation of R&D spend</td><td>‚úÖ Complete</td></tr>
                <tr><td>Cost Summary</td><td>Breakdown by category</td><td>‚úÖ Complete</td></tr>
            </table>
            <h3>Technical Evidence</h3>
            <table>
                <tr><th>Document</th><th>Description</th><th>Status</th></tr>
                <tr><td>GitLab Repositories</td><td>quotech-frontend, quotech-backend, billing-frontend - 100+ commits, 4 contributors</td><td>‚úÖ Documented</td></tr>
                <tr><td>Notion Research Notes</td><td>100+ pages of research documentation</td><td>‚úÖ Complete</td></tr>
                <tr><td>DREAM Research</td><td>AI foundations documentation</td><td>‚úÖ Complete</td></tr>
                <tr><td>Experiment Logs</td><td>Metrics, plots, configurations</td><td>‚úÖ Complete</td></tr>
            </table>
            <h3>Research Notes</h3>
            <table>
                <tr><th>Document</th><th>Description</th><th>Status</th></tr>
                <tr><td>FY25 Research Journal</td><td>Weekly R&D activity log - Q1-Q4</td><td>‚úÖ Complete</td></tr>
                <tr><td>Existing Knowledge Search</td><td>Literature review, commercial analysis, expert consultations</td><td>‚úÖ Complete</td></tr>
            </table>
            <h3>Evidence Cross-Reference Matrix</h3>
            <table>
                <tr><th>Application Section</th><th>Supporting Evidence</th></tr>
                <tr><td>Hypothesis</td><td>DREAM Research, Quotech Project Context, Research Journal Q1</td></tr>
                <tr><td>New Knowledge</td><td>Research Journal (all quarters), DREAM Research</td></tr>
                <tr><td>Existing Knowledge Search</td><td>Previous Filings Analysis, Notion Documentation</td></tr>
                <tr><td>Experiment Design</td><td>Research Journal, GitLab Evidence, Feature Specs</td></tr>
                <tr><td>Evaluation Methodology</td><td>Research Journal Q2-Q4, Technical Documentation</td></tr>
                <tr><td>Conclusions</td><td>Research Journal Q4, Cross-company testing notes</td></tr>
                <tr><td>Expenditure</td><td>Excel Workings, Xero Evidence, Timesheet Summary</td></tr>
            </table>
        </section>

        <!-- DOCUMENTS SECTION -->
        <section id="documents" class="section">
            <h2>üìÑ Document Files</h2>
            <p>Click any document to view its full content:</p>
            
            <h3>Filing Documents</h3>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üìã FY25-RDTI-Application-Content.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 03-filing-documents/FY25-RDTI-Application-Content.md</p>
                    <p>Complete application text with all portal fields including project objectives, records kept, plant and facilities, and beneficiary information.</p>
                </div>
            </div>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üìã FY25-Core-Activities-Complete.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 03-filing-documents/FY25-Core-Activities-Complete.md</p>
                    <p>Complete core activity descriptions including hypotheses, experiment design, evaluation methodology, conclusions, and new knowledge generated.</p>
                </div>
            </div>

            <h3>Technical Documentation</h3>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üß† dream-research-ai-foundations.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 02-evidence/technical/dream-research-ai-foundations.md</p>
                    <p>Foundational AI research from DREAM project including: Core research problem (context window limitation), Intelligent Context Network architecture, Highway metaphor for AI memory, Brain Layer with DeepSeek, Multi-agent orchestration patterns.</p>
                </div>
            </div>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üìê quotech-comprehensive-project-context.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 02-evidence/technical/quotech-comprehensive-project-context.md</p>
                    <p>Complete technical context including: Problem statement, 14 module specifications, Entity data model, Technology stack, Product roadmap, Success metrics.</p>
                </div>
            </div>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üíª gitlab-repository-evidence.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 02-evidence/technical/gitlab-repository-evidence.md</p>
                    <p>Code repository evidence: quotech-frontend (React 19, 100+ commits), quotech-backend (Python/Django), billing-frontend, 4 contributors, technology stack details.</p>
                </div>
            </div>

            <h3>Research Notes</h3>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üìì FY25-Research-Journal.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 02-evidence/research-notes/FY25-Research-Journal.md</p>
                    <p>Weekly R&D activity log covering: Q1 Foundation (context nodes, embeddings), Q2 Optimization (latency, quote reading), Q3 Refinement (neuroplasticity, COT logging), Q4 Validation (cross-company testing, scale).</p>
                </div>
            </div>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üîç FY25-Existing-Knowledge-Search.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 02-evidence/research-notes/FY25-Existing-Knowledge-Search.md</p>
                    <p>Comprehensive search documentation: Academic databases (IEEE, ACM, arXiv), Commercial solutions (Procore, Simpro, etc.), Patent searches, Expert consultations.</p>
                </div>
            </div>

            <h3>Financial Evidence</h3>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üí∞ xero-rdti-accounts-evidence.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 02-evidence/financial/xero-rdti-accounts-evidence.md</p>
                    <p>Chart of accounts verification, P&L figures, journal entry summary.</p>
                </div>
            </div>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üìä fy25-rdti-cost-summary.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 02-evidence/financial/fy25-rdti-cost-summary.md</p>
                    <p>R&D cost breakdown: Wages $520,412.60, Contracted Services $187,425.36, IT & Subscriptions $41,656.87, Rental $21,924.44.</p>
                </div>
            </div>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> ‚è±Ô∏è timesheet-summary-fy25.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 02-evidence/time-records/timesheet-summary-fy25.md</p>
                    <p>Employee R&D time allocation summary with weekly breakdown and R&D percentages.</p>
                </div>
            </div>

            <h3>Evidence Index</h3>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üìä EVIDENCE-INDEX-FY25.md
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> 02-evidence/EVIDENCE-INDEX-FY25.md</p>
                    <p>Master index of all evidence supporting FY25 RDTI application with cross-reference matrix.</p>
                </div>
            </div>

            <h3>Previous Applications</h3>
            <div class="doc-accordion">
                <div class="doc-accordion-header" onclick="toggleAccordion(this)">
                    <span class="icon">‚ñ∂</span> üìÑ Previous RDTI Filings Analysis
                </div>
                <div class="doc-accordion-content">
                    <p><strong>Location:</strong> previous_applications/</p>
                    <p>FY23 RDTI.pdf, FY24 RDTI.pdf - Demonstrating project continuity and progression from prior years.</p>
                </div>
            </div>
        </section>
    </div>

    <footer>
        <div>Bravada Group Pty Ltd | ABN 58167664815</div>
        <div>Unit 3, 10 Pilgrim Court, Ringwood VIC 3134</div>
        <div>Document generated: December 2025</div>
        <div>R&amp;D Tax Incentive Application FY2024-25</div>
        <div style="margin-top: 1rem; opacity: 0.7;">
            <a href="http://bravada-rdti-fy25-58167664815.s3-website-ap-southeast-2.amazonaws.com/" style="color: #4fd1c5;">S3 Website</a> |
            <a href="https://github.com/vastdreams/bravada-rdti-fy25" style="color: #4fd1c5;">GitHub Repository</a>
        </div>
    </footer>

    <script>
        function copyContent(btn) {
            const content = btn.parentElement.querySelector('.content').innerText;
            navigator.clipboard.writeText(content).then(() => {
                const original = btn.innerText;
                btn.innerText = '‚úì Copied!';
                setTimeout(() => { btn.innerText = original; }, 2000);
            });
        }

        function toggleAccordion(header) {
            const content = header.nextElementSibling;
            const isOpen = content.classList.contains('open');
            
            // Close all other accordions
            document.querySelectorAll('.doc-accordion-content.open').forEach(el => {
                el.classList.remove('open');
                el.previousElementSibling.classList.remove('open');
            });
            
            // Toggle this one
            if (!isOpen) {
                content.classList.add('open');
                header.classList.add('open');
            }
        }
    </script>
</body>
</html>
