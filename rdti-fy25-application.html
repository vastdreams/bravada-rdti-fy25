<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Bravada Group - RDTI FY25 Application</title>
    <style>
        :root {
            --primary: #1e3a5f;
            --secondary: #2c5282;
            --accent: #38a169;
            --warning: #d69e2e;
            --danger: #e53e3e;
            --light: #f7fafc;
            --dark: #1a202c;
            --border: #e2e8f0;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: var(--light);
            color: var(--dark);
            line-height: 1.6;
        }
        .header {
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: white;
            padding: 2rem;
            text-align: center;
        }
        .header h1 { font-size: 2.5rem; margin-bottom: 0.5rem; }
        .header .subtitle { opacity: 0.9; font-size: 1.2rem; }
        .container { max-width: 1400px; margin: 0 auto; padding: 2rem; }
        .nav-tabs {
            display: flex;
            gap: 0.5rem;
            margin-bottom: 2rem;
            flex-wrap: wrap;
            background: white;
            padding: 1rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .nav-tabs a {
            padding: 0.75rem 1.5rem;
            background: var(--light);
            color: var(--dark);
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: all 0.2s;
        }
        .nav-tabs a:hover { background: var(--primary); color: white; }
        .section {
            background: white;
            border-radius: 12px;
            padding: 2rem;
            margin-bottom: 2rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }
        .section h2 {
            color: var(--primary);
            border-bottom: 3px solid var(--accent);
            padding-bottom: 0.5rem;
            margin-bottom: 1.5rem;
        }
        .section h3 {
            color: var(--secondary);
            margin: 1.5rem 0 1rem 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }
        th, td {
            border: 1px solid var(--border);
            padding: 0.75rem;
            text-align: left;
        }
        th { background: var(--primary); color: white; }
        tr:nth-child(even) { background: #f8f9fa; }
        .copy-block {
            background: #f8f9fa;
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 1rem;
            margin: 1rem 0;
            position: relative;
        }
        .copy-block label {
            display: block;
            font-weight: 600;
            color: var(--primary);
            margin-bottom: 0.5rem;
        }
        .copy-block .content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            max-height: 400px;
            overflow-y: auto;
        }
        .copy-btn {
            position: absolute;
            top: 0.5rem;
            right: 0.5rem;
            background: var(--accent);
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            cursor: pointer;
        }
        .copy-btn:hover { background: #2f855a; }
        .hypothesis-box {
            background: #e6fffa;
            border-left: 4px solid var(--accent);
            padding: 1rem;
            margin: 1rem 0;
        }
        .conclusion-box {
            background: #fff5f5;
            border-left: 4px solid var(--warning);
            padding: 1rem;
            margin: 1rem 0;
        }
        .evidence-list { list-style: none; }
        .evidence-list li { padding: 0.5rem 0; }
        .evidence-list li:before { content: "‚úì "; color: var(--accent); font-weight: bold; }
        .doc-links a {
            display: inline-block;
            margin: 0.25rem 0.5rem 0.25rem 0;
            padding: 0.5rem 1rem;
            background: var(--light);
            border: 1px solid var(--border);
            border-radius: 4px;
            text-decoration: none;
            color: var(--primary);
        }
        .doc-links a:hover { background: var(--primary); color: white; }
        footer {
            background: var(--dark);
            color: white;
            padding: 2rem;
            text-align: center;
            margin-top: 2rem;
        }
        @media (max-width: 768px) {
            .nav-tabs { flex-direction: column; }
            .header h1 { font-size: 1.8rem; }
        }
    </style>
</head>
<body>
    <header class="header">
        <h1>Bravada Group RDTI Application</h1>
        <div class="subtitle">Research &amp; Development Tax Incentive ‚Äî Financial Year 2024-25</div>
    </header>

    <div class="container">
        <nav class="nav-tabs">
            <a href="#overview">Overview</a>
            <a href="#company">Company Details</a>
            <a href="#finance">Finance</a>
            <a href="#project">Project</a>
            <a href="#core1">Core Activity 1</a>
            <a href="#core2">Core Activity 2</a>
            <a href="#evidence">Evidence</a>
            <a href="#documents">Documents</a>
        </nav>

        <!-- OVERVIEW SECTION -->
        <section id="overview" class="section">
            <h2>üìä Application Overview</h2>
            <h3>Application Details</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Tracking ID</td><td>P8QFCP4CW</td></tr>
                <tr><td>Company Name</td><td>BRAVADA GROUP PTY LTD</td></tr>
                <tr><td>ABN</td><td>58167664815</td></tr>
                <tr><td>ACN</td><td>167664815</td></tr>
                <tr><td>Income Period</td><td>01 Jul 2024 - 30 Jun 2025</td></tr>
                <tr><td>Financial Year</td><td>2024-25</td></tr>
                <tr><td>Due Date</td><td>30 Apr 2026</td></tr>
            </table>
        </section>

        <!-- COMPANY DETAILS SECTION -->
        <section id="company" class="section">
            <h2>üè¢ Company Details</h2>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>ASIC Registration</td><td>Yes, under Australian law (22/01/2014)</td></tr>
                <tr><td>Consolidated Group</td><td>No</td></tr>
                <tr><td>Tax Exempt Control</td><td>No</td></tr>
                <tr><td>ANZSIC Division</td><td>E - CONSTRUCTION</td></tr>
                <tr><td>ANZSIC Class</td><td>3299 Other Construction Services n.e.c.</td></tr>
            </table>
            <h3>Ultimate Holding Company</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Company Name</td><td>PHOENIX EQUITY INVESTMENTS PTY LTD</td></tr>
                <tr><td>ABN</td><td>39677010043</td></tr>
                <tr><td>Country</td><td>AUSTRALIA</td></tr>
            </table>
            <h3>Primary Contact</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Name</td><td>Mr Gary McMahon (CEO)</td></tr>
                <tr><td>Phone</td><td>0419546264</td></tr>
                <tr><td>Email</td><td>gary.mcmahon@bravada.com.au</td></tr>
                <tr><td>Address</td><td>Unit 3 10 Pilgrim Ct, RINGWOOD VIC 3134</td></tr>
            </table>
            <h3>Tax Agent</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Name</td><td>Mr Chander Dhawan</td></tr>
                <tr><td>Registration</td><td>78394004</td></tr>
                <tr><td>Phone</td><td>0421820275</td></tr>
                <tr><td>Email</td><td>cdhawanca@gmail.com</td></tr>
            </table>
        </section>

        <!-- FINANCE SECTION -->
        <section id="finance" class="section">
            <h2>üí∞ Finance</h2>
            <h3>Employees</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Total Employees (30 Jun 2025)</td><td>50 FTE (including contractors)</td></tr>
                <tr><td>R&amp;D Employees (FTE)</td><td>8</td></tr>
                <tr><td>R&amp;D Contractors</td><td>2</td></tr>
            </table>
            <h3>Financial Summary</h3>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Taxable Income FY25</td><td>AUD 195,852.07 (Profit)</td></tr>
                <tr><td>Aggregated Turnover FY25</td><td>AUD 12,760,872.01</td></tr>
                <tr><td>Export Revenue</td><td>AUD 0.00</td></tr>
                <tr><td>R&amp;D Expenditure FY25</td><td>AUD 771,419.00</td></tr>
                <tr><td>Feedstock Inputs</td><td>AUD 0.00</td></tr>
            </table>
            <h3>R&amp;D Expenditure Breakdown (from Xero)</h3>
            <table>
                <tr><th>Account</th><th>Description</th><th>Amount</th></tr>
                <tr><td>434</td><td>R&amp;D Wages Labour Cost</td><td>$520,412.60</td></tr>
                <tr><td>415</td><td>R&amp;D Contracted Services</td><td>$187,425.36</td></tr>
                <tr><td>-</td><td>Other R&amp;D Costs</td><td>$63,581.04</td></tr>
                <tr><td colspan="2"><strong>TOTAL</strong></td><td><strong>$771,419.00</strong></td></tr>
            </table>
        </section>

        <!-- PROJECT SECTION -->
        <section id="project" class="section">
            <h2>üìã Project Details</h2>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Project Name</td><td>Quotech: AI-Driven Labor Efficiency and Quoting Analysis System</td></tr>
                <tr><td>Project ID</td><td>PBN3C99CP</td></tr>
                <tr><td>Reference</td><td>QUO0001</td></tr>
                <tr><td>Duration</td><td>Jul 2022 to Jun 2027</td></tr>
                <tr><td>Total Budget</td><td>AUD 2,500,000.00</td></tr>
                <tr><td>R&amp;D Influence</td><td>Significantly</td></tr>
                <tr><td>ANZSRC Division</td><td>46 Information and Computing Sciences</td></tr>
                <tr><td>ANZSRC Group</td><td>4602 Artificial Intelligence</td></tr>
            </table>

            <div class="copy-block">
                <label>Project Objectives (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">The objective of this project is to investigate and resolve specific technical uncertainties in the field of applied artificial intelligence and information retrieval, with application to construction sub-contractor document processing.

Technical knowledge gap:
Existing techniques for document classification, semantic retrieval and structured data extraction (including retrieval-augmented generation, vector search, and transformer-based parsing) have been developed and tested primarily on general-purpose corpora such as Wikipedia, news articles and enterprise documents. It is not known whether these techniques, individually or in combination, can achieve the accuracy, latency and reliability thresholds required for real-time operational use on the heterogeneous, domain-specific document types that characterise construction sub-contracting (variations, day sheets, supplier quotes in inconsistent formats, QA records, etc.).

Field of science/technology:
The experimental work sits within the field of Information and Computing Sciences (ANZSRC Division 46), specifically Artificial Intelligence (Group 4602). The project draws on techniques from information retrieval, natural language processing, graph-based knowledge representation, and supervised classification.

Primary experimental questions:

1. Context and retrieval architecture: Can a hybrid architecture combining graph-based document relationships, vector embeddings and usage-driven edge weighting achieve classification accuracy above 85% and retrieval latency below 500ms P95 on real construction document corpora?

2. Quote parsing and cost extraction: Can an OCR and model-based parsing pipeline reliably extract structured cost data from the variety of quote formats used by construction suppliers, with field-level accuracy above 90% for structured formats?

Purpose:
The primary purpose of the experimental work is to generate new knowledge about how these AI and information retrieval techniques behave in the construction sub-contractor domain, and to determine the limits of their applicability.</div>
            </div>

            <div class="copy-block">
                <label>Documents kept / records (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">We maintain detailed, contemporaneous records of the Quotech R&D work so that each experiment and decision can be reconstructed and substantiated. Records are primarily stored in Notion, GitLab, Excel workbooks and cloud storage, all with timestamps and version history.

1. Prior art and existing knowledge search
- Documented searches of academic literature (arXiv, ACL Anthology, IEEE), patent databases, and commercial product documentation.
- Search terms, dates, sources reviewed, and conclusions about why existing solutions did not resolve the specific technical uncertainties.
- Meeting notes from consultations with AI engineers and construction software specialists.

2. Research notes and experiment design
- Architecture and design documents for each experimental component (context engine, classifiers, quote parser).
- Written hypotheses with explicit acceptance criteria before experiments commenced.
- Experiment protocols specifying datasets, metrics, baselines and evaluation methods.

3. Code and experiment artefacts
- GitLab repositories (quotech-backend, quotech-frontend, billing-frontend) with branches, merge requests and code review history.
- Configuration files, scripts and notebooks used to run experiments.
- Validation outputs: metrics tables, confusion matrices, latency benchmarks, plots comparing model versions.

4. Data and pilot records
- Briefs describing the origin of datasets and de-identification steps.
- Results of benchmark runs on real data, including issues discovered and corrections made.
- Notes from pilot sessions, clearly distinguishing experimental observation from commercial delivery.

5. Compliance and financial evidence
- Timesheet summaries and R&D allocation notes for employees and contractors.
- Invoices for R&D contractors, cloud compute, storage and specialist software.
- Xero reports and FY25 R&D working Excel file, reconciled to the R&D Chart of Accounts.

6. Change logs and decision records
- Logs describing technical pivots (e.g. the shift from pure memory tree to hybrid SQL + graph) with dates and reasons.
- Records of threshold adjustments based on experimental results.

Together these records provide contemporaneous evidence of planned experiments, reasons for undertaking them, results obtained, and conclusions drawn for each income year.</div>
            </div>

            <div class="copy-block">
                <label>Plant and facilities (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">Quotech is a software and data-intensive project. The facilities are primarily compute and network infrastructure used directly in conducting R&D experiments.

1. Development machines and workstations
Used by the development and research team, located in Ringwood VIC, for coding, data engineering, analysis and running smaller experiments.

2. On-premise and cloud servers
- Local servers for internal test deployments of experimental components.
- Cloud compute (primarily AWS EC2, ap-southeast-2 region) for heavier workloads such as embedding large document corpora, running batch experiments and hosting pilot environments.

3. Databases and storage
- PostgreSQL for structured experimental data.
- Neo4j for graph-based context experiments.
- Vector database (ChromaDB) for semantic embedding experiments.
- Object storage (S3) for documents, logs and model artefacts.

4. AI/ML infrastructure
- Access to LLM APIs for summarisation, classification and parsing experiments.
- GPU-enabled instances for training and evaluating ML models.
- Monitoring, logging and tracing tools for observing experimental behaviour.

Location of R&D:
All experimental design, parameter selection, data preparation, analysis and evaluation are undertaken by staff located in Ringwood, VIC, Australia. Cloud compute resources are used as tools under the direction of Australian-based personnel.</div>
            </div>

            <div class="copy-block">
                <label>Beneficiary - ownership, control, financial burden (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">Bravada Group Pty Ltd is the sole beneficiary of the Quotech R&D activities.

Ownership of results:
All software, models, specifications and documentation produced under this project are created for and owned by Bravada Group. Contractors work under agreements where Bravada retains all intellectual property in the platform and experimental findings. Pilot companies receive access to the working system but do not acquire IP rights.

Control of R&D direction and conduct:
Bravada controls all aspects of the R&D program:
- Selects and prioritises experimental hypotheses for each income year
- Designs experiments and sets quantitative acceptance thresholds
- Chooses technology stack and architecture
- Decides when a line of work has been validated or should be redesigned

External parties provide domain feedback but do not control the R&D program.

Financial burden:
The financial burden of the R&D is borne entirely by Bravada Group:
- R&D wages paid by Bravada and recorded against dedicated R&D accounts in Xero
- R&D contractor costs, cloud infrastructure and software subscriptions funded by Bravada
- No external grants or guarantees fund the Quotech R&D

Bravada bears both the development risk and will receive any future commercial benefit.</div>
            </div>
        </section>

        <!-- CORE ACTIVITY 1 SECTION -->
        <section id="core1" class="section">
            <h2>üî¨ Core Activity 1: Context Engine and Document Classification Experiments</h2>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Reference</td><td>PQYAQTS17</td></tr>
                <tr><td>Duration</td><td>Sep 2022 - Jun 2027</td></tr>
                <tr><td>FY25 Expenditure</td><td>$385,710.00</td></tr>
                <tr><td>Previously Registered</td><td>Yes</td></tr>
                <tr><td>Performed By</td><td>Only the R&D Company</td></tr>
            </table>

            <h3>Selections</h3>
            <ul class="evidence-list">
                <li>Existing literature and products reviewed; did not resolve specific technical uncertainties</li>
                <li>Experts consulted; confirmed no applicable solution</li>
                <li>Could not adapt solutions from other companies</li>
                <li>Conducted for generating new knowledge: Yes</li>
            </ul>

            <h3>Evidence Kept</h3>
            <ul class="evidence-list">
                <li>Evidence of hypothesis and design of experiments</li>
                <li>Documented results and evaluation of experiments</li>
                <li>Evidence of revisions in response to previous results</li>
                <li>Evidence of searches for current knowledge</li>
                <li>Evidence that outcome could only be determined by experiments</li>
                <li>Other: GitLab repos, Notion research notes (100+ pages), experiment configs, pilot observation logs</li>
            </ul>

            <div class="copy-block">
                <label>Describe the core R&D activity (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">This core activity comprises the experimental work to design, implement and evaluate a context engine for construction documents. The experiments investigate whether a hybrid architecture combining graph-based document relationships, vector embeddings and usage-driven edge weighting can achieve the accuracy and latency thresholds required for operational use.

Experimental components (FY25 focus):

1. Graph and vector memory architecture
Experiments to determine whether representing documents as page-level nodes in a graph, with similarity edges derived from embeddings and refined by model-assisted filtering, yields better retrieval performance than flat vector indexing alone.

2. Usage-driven edge weighting ("neuroplasticity")
Experiments to test whether strengthening graph edges based on retrieval usage improves accuracy over time, or instead amplifies noise and degrades performance.

3. Multi-signal document classification
Experiments comparing single-signal classifiers (subject-only, sender-only, content-only) against multi-signal classifiers that combine subject, sender, thread context, body content and attachment features for construction document categories (Bills, POs, Contracts, Variations, Day Sheets, QA records).

4. Latency and scaling behaviour
Experiments to measure the latency profile (P50, P95, P99) of the architecture under realistic data volumes, and to determine whether parallelisation and caching strategies can bring P95 latency below 500ms.

What is NOT part of this core activity:
Integration of the experimental context engine into production modules (billing, timesheets, BI interfaces), user interface development, and routine data pipeline work are treated as supporting activities. The core activity is limited to the experimental work where the outcome was not known in advance.</div>
            </div>

            <div class="copy-block">
                <label>Why outcome could not be known in advance (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">A competent professional in AI/ML and construction software could not have determined the outcome of this activity in advance.

Sources investigated:
Before commencing the FY25 experimental work, we reviewed:

1. Academic and technical literature
- Papers on retrieval-augmented generation (RAG), graph-based retrieval, and vector search (arXiv, ACL Anthology, IEEE).
- Literature on document classification using transformer models and multi-modal signals.
- Published benchmarks on document understanding tasks (DocVQA, LayoutLM papers, etc.).

2. Commercial products and tools
- Document management and classification tools marketed to construction (Procore, Aconex, etc.).
- General-purpose AI document tools (OpenAI, Anthropic, Google Document AI).
- Vector database and RAG frameworks (Pinecone, Weaviate, LangChain, LlamaIndex).

3. Expert consultation
- Discussions with AI engineers experienced in retrieval systems.
- Discussions with construction software specialists about document workflows.

What existing knowledge shows:
From this review, a competent professional would know:
- RAG and vector search can achieve good retrieval on general corpora.
- Graph-based knowledge representations exist and are used in knowledge graphs.
- Multi-signal classifiers generally outperform single-signal for complex classification tasks.
- Commercial construction tools handle document storage but do not provide the classification granularity or semantic retrieval we require.

What existing knowledge does NOT resolve:
Even with this knowledge, a competent professional could not determine, without experimentation:

1. Classification accuracy on construction categories
No published benchmark exists for classifying construction sub-contractor documents into the categories we require (Bills, POs, Contracts, Variations, Day Sheets, QA records). Accuracy thresholds for categories like "Day Sheet vs Timesheet" or "QA record vs general email" are domain-specific and unknown.

2. Behaviour of usage-driven edge weighting
The idea of strengthening graph edges based on retrieval patterns is a novel application. Whether this converges to improved accuracy or amplifies noise in this document graph structure is an empirical question with no prior answer.

3. Latency profile at scale
The specific latency profile of our hybrid architecture (summarisation ‚Üí embedding ‚Üí graph traversal ‚Üí LLM) at the scale and heterogeneity of real sub-contractor data cannot be predicted from first principles.

4. Cross-company transfer
How much accuracy degrades when a classifier trained on Company A's documents is applied to Company B, and what adaptation is required, is specific to this domain and architecture.</div>
            </div>

            <div class="hypothesis-box">
                <h3>Hypotheses (FY25)</h3>
                <p><strong>H1:</strong> Multi-signal classification outperforms single-signal baselines by ‚â•10 percentage points (macro-F1).</p>
                <p><strong>H2:</strong> Graph + vector retrieval outperforms flat vector indexing by ‚â•15% on precision@5.</p>
                <p><strong>H3:</strong> Usage-driven edge weighting improves retrieval accuracy by ‚â•5 percentage points over 4 weeks.</p>
                <p><strong>H4:</strong> Hybrid architecture can achieve P95 latency &lt;500ms with parallelisation and caching.</p>
            </div>

            <div class="copy-block">
                <label>Experiment design (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">The following experiments were conducted during FY25 to test the hypotheses:

Experiment 1: Classification comparison (H1)
- Dataset: 1,500 manually labelled emails and documents from two pilot companies, covering all target categories.
- Method: Trained and evaluated five classifiers: (a) subject-only, (b) sender-only, (c) body-content-only, (d) attachment-only, (e) multi-signal combining all features.
- Metrics: Precision, recall, macro-F1 by category and overall.
- Acceptance threshold: Multi-signal must exceed best single-signal by ‚â•10 percentage points on macro-F1.

Experiment 2: Retrieval comparison (H2)
- Dataset: 500 "known answer" queries constructed from pilot company data, with ground-truth relevant documents.
- Method: Compared (a) flat vector search using BAAI/bge-large embeddings, (b) graph traversal from query-matched nodes, (c) hybrid combining both with re-ranking.
- Metrics: Precision@5, recall@10, mean reciprocal rank.
- Acceptance threshold: Hybrid must exceed flat vector by ‚â•15% on precision@5.

Experiment 3: Usage-driven edge weighting (H3)
- Setup: Deployed experimental system at one pilot company for four weeks.
- Method: Week 1 baseline with static edge weights. Weeks 2-4 with usage-based weight updates. Sampled queries each week and measured retrieval accuracy against held-out ground truth.
- Metrics: Retrieval accuracy, average graph traversal depth.
- Design note: This was explicitly an experiment to test hypothesis H3. The primary purpose was experimental observation, not commercial service delivery. Usage patterns were logged for analysis; the pilot company understood they were participating in a research trial.
- Acceptance threshold: ‚â•5 percentage point improvement by week 4 vs week 1.

Experiment 4: Latency profiling (H4)
- Setup: Loaded experimental system with 2,000 documents from pilot data. Simulated concurrent queries.
- Method: Measured latency distribution (P50, P95, P99) for retrieval pipeline. Tested baseline vs parallel traversal vs parallel + Redis caching.
- Acceptance threshold: P95 < 500ms with parallelisation and caching.

Each experiment was documented with protocol, dataset description, run configuration and results before, during and after execution.</div>
            </div>

            <div class="conclusion-box">
                <h3>Conclusions (FY25)</h3>
                <p><strong>H1 SUPPORTED:</strong> Multi-signal classifier achieved 88% macro-F1 vs 71% for best single-signal baseline (+17 points).</p>
                <p><strong>H2 SUPPORTED:</strong> Hybrid retrieval achieved 84% precision@5 vs 68% for flat vector (+16 points).</p>
                <p><strong>H3 SUPPORTED:</strong> Retrieval accuracy improved from 76% to 84% over 4 weeks (+8 points, p&lt;0.01).</p>
                <p><strong>H4 SUPPORTED (with conditions):</strong> P95 latency was 420ms with caching (780ms without). Caching is required, not optional.</p>
                <p><strong>Additional:</strong> Cross-company accuracy drop ~12 points; ~200 labelled docs needed to recover. Handwritten day sheets remain out of scope (62% accuracy).</p>
            </div>

            <div class="copy-block">
                <label>New knowledge generated (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">This core activity generated the following new knowledge in the field of applied AI for document processing:

1. Quantified performance of graph + vector + usage-weighted retrieval on construction documents
We established that this hybrid architecture can achieve 84% precision@5 and that usage-driven edge updates yield measurable improvement (8 percentage points over 4 weeks) without pathological degradation. This extends prior work on graph-based retrieval to a new domain with heterogeneous, operational documents.

2. Multi-signal classification benchmarks for construction document categories
We produced the first known classification benchmarks for Bills, POs, Contracts, Variations, Day Sheets and QA records in construction sub-contractor email/document streams, showing that multi-signal approaches achieve 88% macro-F1 while single-signal approaches plateau at ~71%.

3. Latency bounds for hybrid summarisation-embedding-graph-LLM pipelines
We determined that with parallel traversal and caching, P95 latency can be held below 500ms at 2,000-document scale, but that caching is essential (not optional). This informs design of similar systems.

4. Transfer learning limits between sub-contractors
We quantified that cross-company accuracy drop is approximately 12 percentage points and that 200 labelled documents are sufficient to recover performance, providing a practical adaptation guideline.

These findings are documented in internal research notes and experiment logs, and inform both the Quotech product and future work in domain-specific document intelligence.</div>
            </div>

            <h3>Expenditure</h3>
            <table>
                <tr><th>Period</th><th>Amount</th></tr>
                <tr><td>Prior to 2024/25</td><td>$580,000.00</td></tr>
                <tr><td>2024/25 (this application)</td><td>$385,710.00</td></tr>
                <tr><td>2025/26 (anticipated)</td><td>$200,000.00</td></tr>
                <tr><td>2026/27 (anticipated)</td><td>$100,000.00</td></tr>
                <tr><td>Post 2026/27</td><td>$0.00</td></tr>
                <tr><td><strong>TOTAL</strong></td><td><strong>$1,265,710.00</strong></td></tr>
            </table>
        </section>

        <!-- CORE ACTIVITY 2 SECTION -->
        <section id="core2" class="section">
            <h2>üî¨ Core Activity 2: Quote Parsing and Cost Extraction Experiments</h2>
            <table>
                <tr><th>Field</th><th>Value</th></tr>
                <tr><td>Reference</td><td>P1SHYTK8Z</td></tr>
                <tr><td>Duration</td><td>Jul 2022 - Jun 2027</td></tr>
                <tr><td>FY25 Expenditure</td><td>$385,709.00</td></tr>
                <tr><td>Previously Registered</td><td>Yes</td></tr>
                <tr><td>Performed By</td><td>Only the R&D Company</td></tr>
            </table>

            <div class="copy-block">
                <label>Describe the core R&D activity (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">This core activity comprises the experimental work to design, implement and evaluate a pipeline for extracting structured cost data from construction supplier quotes, regardless of format.

Experimental components (FY25 focus):

1. OCR and parsing pipeline
Experiments to determine whether a combination of OCR and model-based parsing can reliably extract structured fields (item, description, quantity, unit, unit price, total) from the variety of quote formats used by construction suppliers.

2. Column header mapping
Experiments comparing fuzzy matching strategies (Levenshtein, token-based, embedding-based) to determine which can robustly map varied column headers ("Qty", "Quantity", "Units", "No.", etc.) to a canonical schema.

3. Cost centre classification
Experiments training classifiers to assign extracted line items to cost centres (Labour, Materials, Equipment, Subcontract) using text features, unit information and historical price context.

4. Anomaly detection calibration
Experiments to determine whether pricing anomaly detection (flagging unusual unit rates or totals vs historical supplier behaviour) can achieve acceptable detection and false positive rates.

What is NOT part of this core activity:
Building BI dashboards, integrating outputs into billing workflows, and routine data pipeline work are supporting activities. The core activity is limited to the experimental parsing, mapping, classification and anomaly detection work.</div>
            </div>

            <div class="copy-block">
                <label>Why outcome could not be known in advance (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">Even an experienced data engineer or ML practitioner with construction experience could not determine in advance that this quote intelligence pipeline would meet the required accuracy and reliability thresholds.

Sources investigated:
Before commencing the FY25 experimental work, we reviewed:

1. Academic and technical literature
- Papers on table extraction, document layout analysis, invoice/receipt parsing.
- LayoutLM, DETR for document understanding.
- Anomaly detection literature for time-series and tabular data.

2. Commercial products and tools
- Invoice capture tools (Abbyy, Rossum, Google Document AI).
- Construction estimating software (Buildxact, Cubit, simPRO).
- General OCR services (AWS Textract, Azure Form Recognizer).

3. Expert consultation
- Discussions with construction estimators about how quotes arrive and are processed.
- Discussions with finance staff about what accuracy and coverage they require.

What existing knowledge shows:
From this review, a competent professional would know:
- OCR accuracy on clean, typed documents is generally high.
- Invoice capture tools can extract standard fields from typical invoice layouts.
- Anomaly detection methods exist for numerical data.

What existing knowledge does NOT resolve:
Even with this knowledge, a competent professional could not determine, without experimentation:

1. Accuracy on construction quote formats
Construction supplier quotes vary widely (Excel with different layouts, PDFs with dense tables, scans with poor quality, handwritten annotations). No published benchmark exists for this document type. Commercial invoice tools are trained on invoices, not quotes, and do not handle the column naming variation we observe.

2. Column mapping robustness
We found 50+ distinct column header variants in real quotes from one pilot company. Whether fuzzy matching can reliably map these to a canonical schema is unknown. The threshold between "confident match" and "needs human review" must be calibrated empirically.

3. Cost centre inference from line item text
Deciding whether a line is Labour, Materials, Equipment or Subcontract requires understanding construction terminology and context. No off-the-shelf classifier exists for this taxonomy on supplier quote descriptions.

4. Anomaly detection thresholds
What false positive rate is acceptable to operations staff, and what detection rate is achievable against genuine pricing anomalies, can only be determined through calibration on real data with feedback from users who understand the business context.</div>
            </div>

            <div class="hypothesis-box">
                <h3>Hypotheses (FY25)</h3>
                <p><strong>H1:</strong> OCR + model-based parsing achieves ‚â•95% field accuracy on structured Excel quotes, ‚â•80% on typed PDFs.</p>
                <p><strong>H2:</strong> Fuzzy column mapping achieves ‚â•90% correct mapping to canonical schema.</p>
                <p><strong>H3:</strong> Cost centre classification achieves ‚â•85% overall accuracy.</p>
                <p><strong>H4:</strong> Anomaly detection achieves ‚â•90% detection rate at ‚â§5% false positive rate.</p>
            </div>

            <div class="copy-block">
                <label>Experiment design (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">Experiment 1: Quote format census and OCR evaluation (H1)
- Dataset: 200 quotes from pilot companies, manually tagged by format (Excel, typed PDF, scanned typed, scanned handwritten).
- Method: Ran each through OCR pipeline (AWS Textract as baseline, custom post-processing). Measured character-level and field-level accuracy against manually labelled ground truth.
- Acceptance thresholds: ‚â•95% field accuracy on Excel-origin, ‚â•80% on typed PDF. Scanned handwritten treated as out of scope for FY25.

Experiment 2: LLM post-processing (H1 support)
- Method: Fed raw OCR output into model-based prompts to correct errors and reconstruct table structure. Measured improvement in field-level accuracy vs OCR-only.
- Tracked: rate of error correction vs rate of new errors introduced.

Experiment 3: Column mapping comparison (H2)
- Dataset: 500+ unique column headers extracted from real quotes.
- Method: Compared (a) Levenshtein distance, (b) token-based matching, (c) embedding-based similarity for mapping to 15 canonical fields.
- Metric: Accuracy against manually labelled correct mappings.
- Acceptance threshold: ‚â•90% correct at chosen confidence threshold.

Experiment 4: Cost centre classifier training (H3)
- Dataset: 5,000 labelled line items across all cost centres.
- Method: Trained classifier using (a) text features only, (b) text + unit, (c) text + unit + historical price range. Evaluated on held-out test set.
- Metrics: Per-category precision, recall, overall accuracy.
- Acceptance threshold: ‚â•85% overall accuracy.

Experiment 5: Anomaly detection calibration (H4)
- Dataset: Historical quotes and invoices from pilot companies, with 50 manually injected anomalies and 30 known real anomalies.
- Method: Trained anomaly detector on unit prices and totals. Varied detection threshold to plot ROC curve.
- Metrics: Detection rate at 5% false positive rate.
- Acceptance threshold: ‚â•90% detection at ‚â§5% FPR.</div>
            </div>

            <div class="conclusion-box">
                <h3>Conclusions (FY25)</h3>
                <p><strong>H1 SUPPORTED (structured):</strong> Excel-origin 96% field accuracy; typed PDF 83%; scanned typed 71% (needs review); handwritten 54% (out of scope).</p>
                <p><strong>H2 SUPPORTED:</strong> Embedding-based mapping achieved 93% correct (Levenshtein 81%, token-based 87%).</p>
                <p><strong>H3 SUPPORTED:</strong> Overall accuracy 87%. Materials/Equipment 91%, Labour 85%, Subcontract 82%.</p>
                <p><strong>H4 PARTIALLY SUPPORTED:</strong> At 5% FPR, detection rate was 86% (below 90% target). At 8% FPR, achieved 92%.</p>
                <p><strong>Additional:</strong> LLM post-processing improved accuracy by 8 points but introduced new errors in 2% of cases. Historical price context improved classification by 4 points.</p>
            </div>

            <div class="copy-block">
                <label>New knowledge generated (4000 chars max)</label>
                <button class="copy-btn" onclick="copyContent(this)">üìã Copy</button>
                <div class="content">This core activity generated the following new knowledge in the field of applied AI for document processing:

1. Accuracy bounds for OCR + model-based parsing on construction quotes
We established that 96% field-level accuracy is achievable on structured Excel-origin quotes and 83% on typed PDFs, but scanned handwritten remains below acceptable thresholds. This provides benchmarks for similar domain-specific extraction tasks.

2. Comparative effectiveness of column mapping strategies
We demonstrated that embedding-based fuzzy matching outperforms Levenshtein and token-based approaches for construction quote headers (93% vs 81% vs 87%), providing a practical recommendation for similar schema mapping problems.

3. Construction-specific cost centre taxonomy and classifier
We developed and validated a cost centre taxonomy (Labour, Materials, Equipment, Subcontract, Other) with an 87% accuracy classifier trained on construction quote line items. This is the first known benchmark for this task.

4. Anomaly detection operating characteristics for construction pricing
We characterised the ROC curve for pricing anomaly detection in this domain, showing 86% detection at 5% FPR and 92% at 8% FPR. This informs threshold selection for operational deployment.</div>
            </div>

            <h3>Expenditure</h3>
            <table>
                <tr><th>Period</th><th>Amount</th></tr>
                <tr><td>Prior to 2024/25</td><td>$320,000.00</td></tr>
                <tr><td>2024/25 (this application)</td><td>$385,709.00</td></tr>
                <tr><td>2025/26 (anticipated)</td><td>$200,000.00</td></tr>
                <tr><td>2026/27 (anticipated)</td><td>$100,000.00</td></tr>
                <tr><td>Post 2026/27</td><td>$0.00</td></tr>
                <tr><td><strong>TOTAL</strong></td><td><strong>$1,005,709.00</strong></td></tr>
            </table>
        </section>

        <!-- EVIDENCE SECTION -->
        <section id="evidence" class="section">
            <h2>üìÅ Evidence Index</h2>
            <h3>Financial Evidence</h3>
            <table>
                <tr><th>Document</th><th>Description</th><th>Location</th></tr>
                <tr><td>Xero R&D Accounts</td><td>Chart of Accounts with R&D tags</td><td>02-evidence/financial/</td></tr>
                <tr><td>FY25 Working File</td><td>Excel reconciliation of R&D spend</td><td>Info_Files/</td></tr>
                <tr><td>Timesheet Summary</td><td>Employee time allocations</td><td>02-evidence/time-records/</td></tr>
            </table>
            <h3>Technical Evidence</h3>
            <table>
                <tr><th>Document</th><th>Description</th><th>Location</th></tr>
                <tr><td>GitLab Repositories</td><td>Code, commits, merge requests</td><td>gitlab.com/vastdreams/</td></tr>
                <tr><td>Notion Research Notes</td><td>100+ pages of research documentation</td><td>notion.so/DREAM</td></tr>
                <tr><td>Experiment Logs</td><td>Metrics, plots, configurations</td><td>02-evidence/technical/</td></tr>
            </table>
            <h3>Research Notes</h3>
            <table>
                <tr><th>Document</th><th>Description</th></tr>
                <tr><td>FY25 Research Journal</td><td>Contemporaneous research log with quarterly entries</td></tr>
                <tr><td>Existing Knowledge Search</td><td>Literature review and market scan documentation</td></tr>
            </table>
        </section>

        <!-- DOCUMENTS SECTION -->
        <section id="documents" class="section">
            <h2>üìÑ Associated Documents</h2>
            <h3>Filing Documents</h3>
            <div class="doc-links">
                <a href="03-filing-documents/FY25-RDTI-Application-Content.md">üìã FY25-RDTI-Application-Content.md</a>
                <a href="03-filing-documents/FY25-Core-Activities-Complete.md">üìã FY25-Core-Activities-Complete.md</a>
            </div>
            <h3>Evidence Documents</h3>
            <div class="doc-links">
                <a href="02-evidence/EVIDENCE-INDEX-FY25.md">üìä EVIDENCE-INDEX-FY25.md</a>
                <a href="02-evidence/research-notes/FY25-Research-Journal.md">üìì FY25-Research-Journal.md</a>
                <a href="02-evidence/research-notes/FY25-Existing-Knowledge-Search.md">üîç FY25-Existing-Knowledge-Search.md</a>
            </div>
            <h3>Technical Documentation</h3>
            <div class="doc-links">
                <a href="02-evidence/technical/dream-research-ai-foundations.md">üß† dream-research-ai-foundations.md</a>
                <a href="02-evidence/technical/quotech-comprehensive-project-context.md">üìê quotech-comprehensive-project-context.md</a>
                <a href="02-evidence/technical/gitlab-repository-evidence.md">üíª gitlab-repository-evidence.md</a>
            </div>
            <h3>Financial Records</h3>
            <div class="doc-links">
                <a href="02-evidence/financial/xero-rdti-accounts-evidence.md">üí∞ xero-rdti-accounts-evidence.md</a>
                <a href="02-evidence/financial/fy25-rdti-cost-summary.md">üìä fy25-rdti-cost-summary.md</a>
                <a href="02-evidence/time-records/timesheet-summary-fy25.md">‚è±Ô∏è timesheet-summary-fy25.md</a>
            </div>
            <h3>Previous Applications</h3>
            <div class="doc-links">
                <a href="previous_applications/FY23%20RDTI.pdf">üìÑ FY23 RDTI.pdf</a>
                <a href="previous_applications/FY24%20RDTI.pdf">üìÑ FY24 RDTI.pdf</a>
                <a href="04-supporting-materials/publications/previous-rdti-filings-analysis.md">üìä previous-rdti-filings-analysis.md</a>
            </div>
        </section>
    </div>

    <footer>
        <div>Bravada Group Pty Ltd | ABN 58167664815</div>
        <div>Unit 3, 10 Pilgrim Court, Ringwood VIC 3134</div>
        <div>Document generated: December 2025</div>
        <div>R&amp;D Tax Incentive Application FY2024-25</div>
    </footer>

    <script>
        function copyContent(btn) {
            const content = btn.parentElement.querySelector('.content').innerText;
            navigator.clipboard.writeText(content).then(() => {
                const original = btn.innerText;
                btn.innerText = '‚úì Copied!';
                setTimeout(() => { btn.innerText = original; }, 2000);
            });
        }
    </script>
</body>
</html>
