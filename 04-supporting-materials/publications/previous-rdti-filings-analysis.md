# PATH: 04-supporting-materials/publications/previous-rdti-filings-analysis.md
# PURPOSE:
# - Comprehensive analysis of previous RDTI filings (FY23 & FY24) for consistency and reference
# - Template and pattern extraction for FY25 filing preparation
#
# ROLE IN ARCHITECTURE:
# - Reference document for FY25 filing structure and language
#
# MAIN EXPORTS:
# - Project evolution timeline
# - Filing format patterns
# - Hypothesis and experiment templates
#
# NON-RESPONSIBILITIES:
# - Does NOT contain FY25 content (see separate filing documents)

---

# Previous RDTI Filings Analysis - FY23 & FY24

## Executive Summary

This document analyzes Bravada Group's previous R&D Tax Incentive applications for FY23 and FY24 to:
1. Understand the filing format and structure
2. Track the evolution of the Quotech project
3. Identify successful patterns for hypothesis, experiment, and evaluation sections
4. Ensure FY25 filing maintains consistency and builds upon prior work

---

## 1. Company Details (Consistent Across Filings)

| Field | Value |
|-------|-------|
| **Company Name** | BRAVADA GROUP PTY LTD |
| **ABN** | 58167664815 |
| **ACN** | 167664815 |
| **Registration Date** | 22/01/2014 |
| **ANZSIC Division** | E - CONSTRUCTION |
| **ANZSIC Class** | 3299 Other Construction Services n.e.c. |
| **Primary Contact** | Gary McMahon, CEO |
| **Address** | Unit 3 10 Pilgrim Ct, RINGWOOD VIC 3134 |
| **Website** | www.bravada.com.au |
| **Tax Advisor** | Chander Dhawan (reg: 78394004) |

### Corporate Structure Evolution
- **FY23**: No Ultimate Holding Company
- **FY24**: Ultimate Holding Company = **Phoenix Equity Investments Pty Ltd** (ABN: 39677010043, registered 01/05/2024)

---

## 2. Project Overview Comparison

### Project Name Evolution

| Year | Project Name | Project ID |
|------|--------------|------------|
| FY23 | QuoTech: AI-Driven Labor Efficiency and Quotation Analysis System | PBN3C99CP |
| FY24 | AI-Driven Labor Efficiency and Quoting Analysis System | PBN3C99CP |
| FY25 | *Quotech: AI-Driven Labor Efficiency and Quoting Analysis* (proposed) | PBN3C99CP |

**Note**: Project ID remains consistent across years, ensuring continuity.

### Project Duration & Budget

| Parameter | FY23 | FY24 | FY25 (Proposed) |
|-----------|------|------|-----------------|
| **Duration** | Jul 2022 - Jun 2026 | Jul 2022 - Jun 2026 | Jul 2022 - Jun 2026 |
| **Total Project Budget** | $1,500,000 | $1,500,000 | $1,500,000 |
| **Annual R&D Expenditure** | $334,100 | $395,370 | ~$771,419 |
| **R&D Staff (FTE)** | 6 | 8 | TBD |
| **Total Employees** | 38 | 45 | TBD |

### Research Field Classification

| Year | ANZSRC Division | ANZSRC Group |
|------|-----------------|--------------|
| FY23 | 46 Information and Computing Sciences | 4611 Machine learning |
| FY24 | 46 Information and Computing Sciences | 4602 Artificial intelligence |

**FY25 Recommendation**: Use **4602 Artificial intelligence** to reflect the agentic AI focus.

---

## 3. Core Activity Evolution

### Core Activity Name Progression

| Year | Core Activity Name | Activity ID |
|------|-------------------|-------------|
| FY23 | ML-based Segmentation and Analysis of Construction Quotations | P1SHYTK8Z |
| FY24 | Email and Document Context Intelligence and Sub-Module Creation: Bills, Timesheets, BI and Information | PQYAQTS17 |
| FY25 | *To be defined - likely continuation of AI-driven modules* | NEW |

---

## 4. Hypothesis Structure Analysis

### FY23 Hypothesis Pattern

**Primary Hypothesis (Commercial Research)**:
> "By employing machine learning algorithms and data rules to segment, categorize, and analyze construction quotations, it is possible to enhance the accuracy of labor hour predictions. This, in turn, will lead to improved efficiency in resource allocation, a reduction in labor-hour wastage, ability to provide discounts on overcharge and a sustainable and stable profit margin. Furthermore, with real-time feedback loops, the AI system can continuously learn and refine its predictions, adapting to changing scenarios and job complexities, using cost categories on scale."

**Sub-Hypotheses**:
1. **Sub-1 (On-Site Labor Complexity)**: Delineate labor hours involving on-site visits using category tags like "installation"
2. **Sub-2 (Industry-Specific Labor Predictions)**: Custom ensemble model blending regression with topic classification
3. **Sub-3 (Timesheet and Material Co-relation)**: Mapping labor hours to specific materials/tasks

### FY24 Hypothesis Pattern

**Primary Hypothesis** (with specific metrics):
> "We hypothesise that a hybrid rule-based and generative AI system, with a continuous growth of general knowledge intelligence specific to company, and sub-categorised query agentic logic, integrated with emails, documents, timesheets, and other ERP or manual quote data, can consistently achieve:
> - Automation in cost categorisation to quotation tasks
> - Resource capacity planning efficiency gains of up to 10-20%
> - +/-10% capacity planning forecasts with estimated pipeline within a 1 week horizon
> - Automate bill and cost intelligence within 80% of scenarios not requiring human loop
> - Latency below 500 ms"

**Sub-Hypotheses**:
- **H1**: Context Library with "Context Bubbles" and directory nodes using AI Search + Elastic Search
- **H2**: Sub-Trained AI for bill reconciliation with PO matching and supplier categorization
- **H3**: Expert Model Agentic AI for timesheets, calendar integration, and BI dashboards

### Pattern for FY25

**Recommended Structure**:
1. State primary hypothesis with **specific, measurable targets**
2. Include **latency/efficiency metrics** (e.g., "< 500ms", "80% automation")
3. Define **3-5 sub-hypotheses** covering distinct technical domains
4. Reference how sub-hypotheses **connect to form the integrated system**

---

## 5. Experiment Design Patterns

### FY23 Experiment Structure

1. **Identification of Possibilities**: Define achievable outcomes and barriers
2. **Data Compilation**: Aggregate quotations, invoices, timesheets
3. **Data Preprocessing**: Cleansing and categorization
4. **Rule-Based Engine Creation**: Historical patterns for predictions
5. **ML Model Development**: Train models for labor hour prediction
6. **Feedback Integration**: Adaptive feedback loop
7. **Category Standardization**: Establish consistent labor categories

**Testing Methodology**:
- Collaborative Analysis (3 primary + 2 external companies)
- Quantitative Retrospective Analysis
- Real-Time Validation
- Industry-Specific Analysis
- Commercial Viability Assessment
- Benchmarking

### FY24 Experiment Structure

**Pilot Setup**:
- Three independent sub-contracting firms
- Combined annual turnover of $18m
- Different ERPs (Xero, Deputy, etc.)
- Three unique data inflows

**System Architecture Elements**:
- Data ingestion → data graphs → agentic logic
- Bill categorization through email feed
- Human-in-the-loop interface for uncertainties

**Test Procedures**:
- Baseline capture
- Entry error and BI data comparison (manual vs. automation)
- A/B methods for workflow structuring

---

## 6. Evaluation Metrics Comparison

### FY23 Numeric Metrics

| Metric | Formula/Description |
|--------|---------------------|
| **Discrepancy Percentage** | (Quoted Hours - Actual Hours) / Quoted Hours × 100 |
| **Accuracy Leak Rate** | Projects with Leaks / Total Monitored × 100 |
| **Tolerance Deviation** | Instances Beyond Tolerance / Total Predictions × 100 |
| **Predictive Precision** | Σ((Predicted - Actual) / Actual) / N × 100 |
| **Category Accuracy** | Correct categorizations vs. manual classification |
| **Feedback Loop Efficacy** | 100% - (Post-Feedback Error / Pre-Feedback Error × 100) |

### FY24 Numeric Metrics

| Metric | Description |
|--------|-------------|
| **% Accuracy** | Per data table (Billing, Timesheet, Labour Cost Centre, etc.) |
| **Accuracy Leak Rate** | Manual input prompts and avoidance rate |
| **Cost Utilisation** | Per query chain, with defined ROI thresholds |
| **Category Accuracy** | Subjective categorization vs. manual review |
| **Latency** | Response time targets |

**Cost Thresholds Defined**:
- Timesheet query: < $0.005 per query chain per project
- Document categorization: < $0.001 per email/document

---

## 7. Conclusions Reached

### FY23 Conclusions
> "No major conclusions were reached, as we are in the process of structuring data and testing the hypothesis and creating sub-hypothesis to achieve the primary hypothesis."

### FY24 Conclusions

1. **Sub-Agentic AI models** need single LLM chains for specific task structuring
2. **Database tagging** needs pre-tagging on categorization clusters
3. **Context columns** in SQL schema for AI context nodes
4. **General Memory Tree** does not meet retrieval efficiency requirements
5. **Nodal depth mapping (Graphs)** being considered for retrieval
6. **Agentic logic can be rapidly Frameworked** for immediate testing
7. **Chat interface prompting** needs sub-segmentation into manual calendar planning
8. **Logging query sequence in graphical dashboard** allows rapid Human Loop optimization

**Further Research Required**:
1. How information is effectively stored (SQL + context graph combination)
2. API development for each sub-step with blueprint feed
3. Fixed schema for Sub-Contractor Directory Structure

---

## 8. Evidence Kept

### FY23 Evidence Types
- ✅ Evidence of searches/enquiries for current knowledge
- ✅ Evidence showing outcome could only be determined by experiments
- ✅ Evidence of hypothesis and experiment design
- ✅ Documented results and evaluation
- ✅ Other: Code base, screens & flow charts, collaboration agreements

### FY24 Evidence Types
- ✅ Same categories as FY23
- ✅ Additional: Pilot company data, API logs, cost utilization tracking

---

## 9. Key Takeaways for FY25 Filing

### Structural Consistency
1. **Maintain Project ID**: PBN3C99CP for continuity
2. **Use consistent project name** with slight evolution
3. **Keep duration at Jul 2022 - Jun 2026** as originally stated
4. **Update ANZSRC to 4602 Artificial intelligence**

### Hypothesis Best Practices
1. Include **specific, measurable targets** (percentages, latencies)
2. Define **connected sub-hypotheses** (H1, H2, H3 pattern)
3. Reference **industry context** (sub-contractors, construction)
4. Mention **technical approach** (agentic AI, multi-model, etc.)

### Experiment Documentation
1. Describe **pilot setup** with specific companies/data sources
2. Detail **system architecture** at a high level
3. Include **test procedures** with controlled baselines
4. Reference **A/B testing** and manual review processes

### Evaluation Metrics
1. Define **specific formulas** where applicable
2. Include **cost thresholds** for commercial viability
3. Reference **latency targets**
4. Note that **p-tests are not viable** for this type of evaluation

### Conclusions
1. Be **specific about what was learned**
2. Acknowledge **what didn't work** (e.g., general memory tree limitations)
3. State **further research required** clearly
4. Reference **technical pivots** when appropriate

---

## 10. Financial Comparison

| Year | R&D Expenditure | Taxable Income | Turnover | R&D Staff |
|------|-----------------|----------------|----------|-----------|
| FY23 | $334,100 | $145,000 | $8,668,000 | 6 FTE |
| FY24 | $395,370 | -$290,783 | $9,016,824 | 8 FTE |
| FY25 | **$771,419** | TBD | TBD | TBD |

**FY25 R&D Expenditure Breakdown** (from Xero):
- R&D Wages Labour Cost: $520,412.60
- R&D Contracted Services: $187,425.36
- R&D IT & Subscription: $41,656.87
- R&D Rental Cost: $21,924.44
- **Total**: $771,419.27

---

## Future Notes for AI

1. **When preparing FY25 filing**: Use the H1/H2/H3 sub-hypothesis pattern from FY24
2. **For experiment section**: Reference the 5 AI modules and their specific testing approaches
3. **For evaluation metrics**: Include cost-per-query thresholds and latency targets
4. **For conclusions**: Reference the DREAM research findings on neuroplasticity and context networks
5. **Maintain continuity**: Reference prior year findings when describing pivots or refinements
